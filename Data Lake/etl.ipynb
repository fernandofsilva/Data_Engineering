{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config.get('AWS', 'AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config.get('AWS', 'AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"Creates the spark session\"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/home/workspace/data/song_data/*/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_table = df.select([\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\"]).dropDuplicates()\n",
    "songs_table.write.mode('overwrite').partitionBy(\"year\", \"artist_id\").parquet(os.path.join(\"data\", \"songs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_table = (df.selectExpr(\"artist_id        as artist_id\", \n",
    "                               \"artist_name      as name\", \n",
    "                               \"artist_location  as location\", \n",
    "                               \"artist_latitude  as latitude\", \n",
    "                               \"artist_longitude as longitude\")\n",
    "                 .dropDuplicates())\n",
    "artists_table.write.mode('overwrite').parquet(os.path.join(\"data\", \"artists\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/home/workspace/data/log_data/*.json\")\n",
    "df = df.filter(\"page = 'NextSong'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table = (df.selectExpr(\"userId    as user_id\",\n",
    "                             \"firstName as first_name\",\n",
    "                             \"lastName  as last_name\",\n",
    "                             \"gender\",\n",
    "                             \"level\")\n",
    "               .dropDuplicates())\n",
    "users_table.write.mode('overwrite').parquet(os.path.join(\"data\", 'users'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_timestamp = udf(lambda x: datetime.fromtimestamp(x / 1000.0).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df = df.withColumn(\"timestamp\", get_timestamp(df.ts))\n",
    "time_table = (df.selectExpr(\"timestamp             as start_time\",\n",
    "                            \"hour(timestamp)       as hour\",\n",
    "                            \"day(timestamp)        as day\",\n",
    "                            \"weekofyear(timestamp) as week\",\n",
    "                            \"month(timestamp)      as month\",\n",
    "                            \"year(timestamp)       as year\",\n",
    "                            \"weekday(timestamp)    as weekday\")\n",
    "                .dropDuplicates())\n",
    "time_table.write.mode('overwrite').partitionBy(\"year\", \"month\").parquet(os.path.join(\"data\", \"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = spark.read.parquet(os.path.join(\"data\", 'songs'))\n",
    "songplays_table = df.join(song_df, \n",
    "                          (df.song     == song_df.title)\n",
    "                          & (df.artist == song_df.artist_id),\n",
    "                          \"left\").selectExpr(\"monotonically_increasing_id() as songplay_id\",\n",
    "                                             \"timestamp                     as start_time\",\n",
    "                                             \"userId                        as user_id\",\n",
    "                                             \"level\",\n",
    "                                             \"song_id\",\n",
    "                                             \"artist_id\",\n",
    "                                             \"sessionId                     as session_id\",\n",
    "                                             \"location\",\n",
    "                                             \"userAgent                     as user_agent\",\n",
    "                                             \"month(timestamp)              as month\",\n",
    "                                             \"year(timestamp)               as year\")\n",
    "songplays_table.write.mode('overwrite').partitionBy(\"year\", \"month\").parquet(os.path.join(\"data\", \"songplays\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
